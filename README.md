# LLM Architecture: Self-Improving Prompt & Intelligent Context Engineering Systems

This repository contains the source code for two interconnected AI engineering projects designed to optimize and automate interactions with Large Language Models (LLMs). The goal is to build a sophisticated system that improves both the prompts sent to an LLM and the context provided with those prompts.

## Projects

This repository is divided into two primary projects, each managed in its own branch:

1.  ### **Project 1: `project-PromptEvolve`**
    *   **Full Title**: Self-Improving Prompt Engineering System.
    *   **Description**: This project implements a co-evolutionary framework that automatically improves and optimizes prompts without needing manual human feedback. It consists of four main components: a `PromptChallenger` to generate prompt variations, a `PromptSolver` to test them, a `PromptVerifier` to evaluate performance, and an `EvolutionEngine` to select the best prompts for the next generation. The system is designed to adapt prompts for various domains like legal research and ontology extraction.

2.  ### **Project 2: `project-ContextCore`**
    *   **Full Title**: Intelligent Context Engineering System.
    *   **Description**: This project focuses on building a pipeline that retrieves, assembles, and optimizes context from diverse data sources such as knowledge graphs (Graphiti) and semantic search (LightRAG). The system aims to provide personalized and token-budget-aware context to improve the relevance and accuracy of AI responses. The architecture follows a flow of Retrieval, Assembly, Optimization, and Personalization.

---
*This project plan spans 8 weeks, with detailed sprints covering foundation, core logic, integration, and refinement.*

